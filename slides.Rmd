---
title: "Field Experiments"
subtitle: "Digital and Social Media Strategies"
author: "Lachlan Deer"
institute: "Tilburg University"
date: "Updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, metropolis, metropolis-fonts]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: font160

# Learning Goals for this Week

* Define the term "field" experiment 
* Identify and explain the key features of field experiments
* Discuss how field experiments allow marketers to make causal claims about their marketing intervention 
* Compute descriptive statistics and visualize data from a field experiment 
* Use statistical hypothesis testing to analyze experimental data and answer a strategic question

---
class: inverse, center, middle

# Preliminaries

---
class: clear 


```{r, echo = FALSE, fig.align = "center", out.width="55%"}
url <- "https://media.makeameme.org/created/and-were-back-5c6cdb.jpg"
knitr::include_graphics(url)
```

---
class: font150
# Schedule Updates

.center[.font130[**We've missed the last two weeks of lectures**]]

<br>

We're going to **catch up** one of them ...

* **This week, on Friday at 16:45**
* (not the best time of the week)
* Needed to give you some context for the group assignment

We're going to drop one lecture from the schedule 

* Still deciding what that will be ... 
* It will be one of the ones "near the end" of the class

---
class: font160
# Where Are We Now? 

Course Themes:

1. Classical Approaches to Measuring Advertising Effects
2. **Modern Evaluation of Digital Advertising Effects**
2. User Generated Content & Social Media
3. Email & Mobile Marketing
4. Issues in (Massive) Online Marketplaces
5. Impact of Privacy Regulations 

---
# Wasteful Advertising Expenditures? 

```{r, echo = FALSE, fig.align = "center", out.width="100%"}
url <- "figs/wannamaker.png"
knitr::include_graphics(url)
```

.right[
Source: [Papergreat Blog](http://www.papergreat.com/2012/09/saturdays-postcard-wanamakers-and-1911.html)
]

---
class: font150
# Measuring Advertising Response

`r icons:::icon_style(icons::fontawesome("bullseye", style = "solid"), scale = 1)`
**The goal of any marketing campaign is to increase sales** 

* Either short-term or long-term

`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**How to evaluate the performance of marketing?**

Each campaign / channel is evaluated on incremental profit that it produces relative to its cost 

$$
ROI = \frac{\text{incremental profit due to advertising} - \text{cost of advertising}}{\text{cost of advertising}}
$$

---
class: font160
# Our learning journey... 

.center[.font120[Popular techniques for estimating the incremental sales due to advertising]]

*Previously*: Marketing Attribution Rules & Media Mix Modelling

* Relies on *observational* data 

**Today**: **Intro to Field Experiments** 

* What are they? Why we run them? How to analyse the data?
* Abstract away from Digital Markets for generalizability

*Friday*: Experiments with Online Display Advertising

---
class: inverse, center, middle

# The Burger Promotion Problem

---
class: font150
# The Burger Promotion Problem: Set up 

```{r, echo = FALSE, fig.align = "center", out.width="50%"}
url <- "https://cdn.vox-cdn.com/thumbor/4mAGUkdlOUBL_INj2X2uZ53BR8U=/0x0:1100x825/1200x800/filters:focal(0x0:1100x825)/cdn.vox-cdn.com/uploads/chorus_image/image/46157824/american-burgers.0.0.jpg"
knitr::include_graphics(url)
```

* New burger to be **introduced to all** stores 
* **Three** different **promotion strategies** used (promo 1, 2 or 3)
* **Managers care about sales**
* No access to previous sales data 

.center[
`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**Which promotion strategy is the most effective?**
]

---
class: font150
# The Burger Promotion Problem

Access to information about store characteristics:

* Market size: Small / Medium / Large 
* Age of store: in years since opening 

You can track: 
* Weekly sales (in hundreds of thousands of dollars) per store
* For up to 4 weeks 

**Discussion Questions**:

**1. How would you allocate promotion strategies to stores?**

**2. How would you evaluate the effectiveness of each promotion strategy?**

.font70[(Two blank slides to sketch out an answer)]

---
class: clear 

---
class: clear 

---
class: font150
# Potential Issues Encountered

<!---

* **Lurking Variables**: variable that is not included as an explanatory or response variable in the analysis but can affect the interpretation of relationships between variables.
  - Also called a confounding variable

<br>

* **Sample Selection Bias**:  Failing to ensure that the sample obtained is representative of the population intended to be analyzed

<br>

* **No Control Group**: Effectiveness compared to no intervention (eg. promotional strategy) 

--->

---
class: font150
# Gold Standard Data Driven Marketing

| "Traditional" Data Driven Marketing | Gold Standard Data Driven Marketing        |
|-------------------------------------|--------------------------------------------|
| Anchor on data that is available    | Anchor on a decision that needs to be made |
| Finds a purpose for data            | Finds data for a purpose                   |
| Starts from what is known           | Start from what is unknown                 |
| Empowers data analysts/scientists   | Empowers decision making                   |


adapted from De Lange and Putoni (2020)

---
class: inverse, center, middle
# Field Experiments 101 

---
class: font150
# Causal Data Driven Marketing

<br>

> What is the impact of an marketing intervention (X) on an outcome (Y)

<br>

1. Hard to evaluate
2. Need to compute counterfactuals
3. Challenge: same person cannot both get treatment and not get treatment

---
class: font150
# Field Experiments 

> Field experimentation represents the conjunction of two methodological strategies: **experimentation** and **fieldwork**.

**Core idea of Experiments**:

```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "figs/random_allocation.png"
knitr::include_graphics(url)
```

.center[along with the observation/measurement of an outcome variable]

---
class: font150
# Field Experiments 

<br>
Key features of a field experiment: 

<br>

1. Authenticity of treatments 
2. Representativeness of participants 
3. Real world context 
4. Relevant outcome measures

<br>

In most field experiments, participants are not even conscious of taking part in an experiment

---
class: font150
# "True" Experiments 

<br>

Three identifiable aspects:

<br>

1. Comparison of outcomes between treatment and control
2. Assignment of subjects is to groups is done through a randomization device
3. Manipulation of treatment is under control of a researcher / analyst


.font70[Dunning, T. (2012). Natural experiments in the social sciences: A design-based approach. Cambridge: Cambridge University Press.]

---
class: font130
# Eight Steps of an Experiment

1. Write down a testable hypothesis.
  * Generally advocate a "no change" hypothesis
2. Decide on two or more treatments that might impact the outcome variable(s) of interest.
  * Generally, include a control treatment where nothing is changed to use as a baseline
3. Compute how many subjects to include in the experiment**.
3. Randomly divide subjects (people/stores) into groups.
  * Also need to decide on the sample size for each group.
4. Expose each group to a different treatment.
5. Measure the response in terms of an outcome variable(s) for subjects in each group.
  * Outcomes must be chosen in advance!
6. Compare responses via a (correct) statistical test.
7. Conclude whether to reject or "fail to reject" your hypothesis based on (7).


* Good experiments have a hypothesis that answers a **strategic question** for a business

---
class: font150
# The Burger Promotion Problem Redux 

```{r, echo = FALSE, fig.align = "center", out.width="50%"}
url <- "https://cdn.vox-cdn.com/thumbor/4mAGUkdlOUBL_INj2X2uZ53BR8U=/0x0:1100x825/1200x800/filters:focal(0x0:1100x825)/cdn.vox-cdn.com/uploads/chorus_image/image/46157824/american-burgers.0.0.jpg"
knitr::include_graphics(url)
```

<br>

* Go back to your proposed solution to measure the effectiveness of the three promotional strategies
* Update your plan using what we have discussed.

---
class: clear

---
class: font140
# Causation and the Rise of Experiments

> **Experiment**: statistical test where a hypothesis is subjected to data produced by a specific procedure in which some variable thought to affect an outcome is deliberately manipulated

Overcomes:

1. Lurking Variables: All lurking variables are uncorrelated with the experiment
2. Selection Bias: Analyst chooses the sample to match the population of interest

Remark: Experiments are often also called A/B tests or A/B/n tests.

---
class: font150
# Causal Data Driven Marketing Redux

<br>

> What is the impact of an marketing intervention (X) on an outcome (Y)

<br>

1. Hard to evaluate
2. Need to compute counterfactuals
3. Challenge: same person cannot both get treatment and not get treatment

.center[
`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**How have field experiments helped us do causal data driven marketing?**
]

---
# Most Experiments Fail

**Main Point of an experiment**:  test some idea 

* *not* proven something 

$\implies$ most experiments "fail"

* i.e. change does not lead to an improvement

**This is a good thing**

* Bad ideas fail quickly
* Investment is typically small ...
* ... as are the sample sizes

But failed experiments are not normally what one sees ...

* In publications, or 
* When talking to a firm 

---
class: inverse, center, middle

# Analyzing Field Experiment Data

---
class: font150
# The Burger Promotion Problem Redux 

```{r, echo = FALSE, fig.align = "center", out.width="50%"}
url <- "https://cdn.vox-cdn.com/thumbor/4mAGUkdlOUBL_INj2X2uZ53BR8U=/0x0:1100x825/1200x800/filters:focal(0x0:1100x825)/cdn.vox-cdn.com/uploads/chorus_image/image/46157824/american-burgers.0.0.jpg"
knitr::include_graphics(url)
```

* New burger to be **introduced to all** stores 
* **Three** different **promotion strategies** used (promo 1, 2 or 3)
* **Managers care about sales**
* No access to previous sales data 

.center[
`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**Which promotion strategy is the most effective?**
]

---
# The Data

```{r, echo = FALSE, message = FALSE}
library(readr)
library(dplyr)
library(janitor)

df <- read_csv("data/WA_Marketing-Campaign.csv") %>%
  clean_names() 
  
df %>%
  head(15)
```

---
class: font160
# Steps to Analyze Experimental Data 

<br>

1. Build an understanding of the data structure 
2. Compute some descriptive statistics 
3. Visualize the Data
4. Run (the correct) statistical test
5. (Use test results to inform decision making)

---
class: font160
# Descriptive Statistics

,center[
`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**What descriptive statistics do you want to know?**
]

<!---
Things you might want to know: 

* How many observations in total? 
* How observations many per treatment?
* What is the mean/median number of sales per store in each treatment group?
* What is the standard deviation of the number of sales per store in each treatment group?
* Do observable characteristics of stores differ across treatments?

There are definitely more ...

--->

---
class: font50
# Descriptive Statistics

```{r, echo = FALSE}
library(skimr)
df %>% skim()
```

---
# Descriptive Statistics By Treatment


```{r, echo = FALSE}
df %>% group_by(promotion) %>% summarize(n_stores = n_distinct(location_id))
```

---
# Descriptive Statistics By Treatment

```{r, echo = FALSE}
df %>%
    distinct(location_id, .keep_all = TRUE) %>%
    select(market_size, age_of_store, market_id, promotion) %>%
    vtable::sumtable(group = "promotion", group.test = TRUE)

```

.center[
$\implies$ **No evidence of differences in store characteristics across treatments**
]

---
class: font160
# (Always) Visualize the Data!

.center[
`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**How to best visualize differences between promotions?**
]

<!---
Alternatives include:

* Histogram / bar plot
* Scatterplot 
* Boxplot
--->

---
# (Always) Visualize the Data!


```{r, message = FALSE, echo = FALSE}
library(ggplot2)
df %>%
  ggplot() +
  geom_boxplot(aes(x = as.factor(promotion), y =sales_in_thousands, fill = promotion)) + 
  theme_bw() + 
  theme(legend.position = "none")
```


---
class: font160
# A Statistical Test

> **What is the "right" statistical analysis to run?**

<!---
Some alternatives:

1. **Two-sample tests of means**
  - Limit to binary comparisons =
2. Two-sample test of proportions
  - We don't have proportions in our data
3. **ANOVA**
4. **Linear Regression**
--->

---
class: font160
# Comparing Means - Two Alternatives

Form null and alternative hypotheses:

* H0: $\mu_1 - \mu_2 = 0$
* HA: $\mu_1 - \mu_2 \neq 0$

Set a level of significance: $\alpha = 0.05$

Test Statistic (assuming unequal variances): 

$$\text{t-stat} = \frac{\hat{\mu}_1 - \hat{\mu}_2}{\sqrt{\left( \frac{\hat{\sigma_1}^2}{n_1} + \frac{\hat{\sigma_2}^2}{n_2} \right)}}$$

---
class: font160
# Comparing Means - Two Alternatives

.center[Compare promotion 1 and promotion 2]

<br>

```{r, echo = FALSE}
library(infer)
df2 <- 
  df %>%
  filter(promotion != 3)

t_test(df2, sales_in_thousands ~ promotion, var.equal = TRUE)
```

`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**How to interpret the output?**


---
# Intermezzo: Type I and Type II errors


```{r, echo = FALSE, fig.align = "center", out.width="65%"}
url <- "https://miro.medium.com/max/852/1*iM4wTvvEgVmFVqbaip2--Q.png"
knitr::include_graphics(url)
```

In experiments at large tech companies usually $\beta = 0.8$

---
class: font150
# Comparing Means >2 Alternatives 

What if we want to compare all treatments?

Need ANOVA:

$$y_{ij} = \mu + \tau_j + \varepsilon_{ij}$$

where $i$ is an observation and $j$ is treatment

Null Hypothesis: 

* H0: $\tau_1$ = $\tau_2$ = $\tau_3$

---
class: font160
# ANOVA: Some details

Assumptions:

1. Independence of Errors 
2. Constant Variance
3. Normality of errors 

Of these, (2) is the most important. 

$\implies$ homoskedasticity

Assuming errors are normally distributed, tested via Bartlett's test 

<!---
* Tested via Bartlett Test.
  * Assumes normality of errors 
* If non-normal: Brown-Forysth test
* If non-constant variance: Cochrane's test
--->

---
class: font160
# Comparing Means >2 Alternatives 

**Bartlett Test**

Null Hypothesis: Variances are equal across treatments

```{r, echo = FALSE}
bartlett.test(sales_in_thousands ~ promotion, data = df)
```
`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**How to interpret the output?**

---
class: font160
# Comparing Means >2 Alternatives 

```{r, echo = FALSE}
summary(aov(sales_in_thousands ~ promotion, data = df))
```

`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**How to interpret the output?**

---
class: font140
# Comparing Means >2 Alternatives 

Are there **differences between treatments**?

* Tukey's Honestly Significant Difference Test
  * Not a bunch of pairwise binary tests
  * Why?  
    - Testing multiple hypotheses...
    - Issues about what the *actual* significance level is 


```{r, echo = FALSE}
library(magrittr)
df %<>%
  mutate(promotion= as.factor(promotion))

TukeyHSD(aov(sales_in_thousands ~ promotion, data = df), "promotion")
```

`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**How to interpret the output?**

---
class: font140
# Regression: Two Promotion Comparison 

$$\text{Sales}_i = \beta_0 + \beta_1 \text{Promotion Type 2} + \varepsilon_i$$

```{r, echo = FALSE}
simple_reg <- lm(sales_in_thousands ~ as.factor(promotion), data = df2)
summary(simple_reg)
```

---
class: font140
# Two Promotion Comparison 

`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**Questions:**

* Why only an estimate of promotion 2 and not also promotion 1?
* How to interpret this regression?

<!---
**Answers:** 

* When a constant is included in the regression 1 categorical variable must be left out ...
  - We have two categories since we have two treatments (promotion 1 and promotion 2)

* $\beta_0$ is the average revenue for stores who were in Promotion 1
* $\beta_0 + \beta_1$ is the average revenue for stores who were in Promotion 2

$\implies$ $\beta_1$ is the average difference in revenue (in 000s) between promotion 2 and promotion 1

--->

---
class: font140
# Causal Interpretations and Experiments 

**Regression estimates from analysis of experiments have causal interpretations**

Why? 

* Counterfactual outcomes - compare to an alternative promotion
* "As good as random" assignment to treatments - lurking variables won't trouble us 
* No sample selection bias ... analyst picked the sample to match the group they care about
  
Regression estimates from experiments allow us to:

* Test whether treatments have effects 
  * Same as ANOVA or a t-test
* Estimate a magnitude of the effect sizes (and standard errors)
  * Which our t-test and ANOVA didn't

---
# Two Promotion Comparison with log Y

$$log(\text{Sales}_i) = \beta_0 + \beta_1 \text{Promotion Type 2} + \varepsilon_i$$

```{r, echo = FALSE}
simple_reg <- lm(log(sales_in_thousands) ~ as.factor(promotion), data = df2)
summary(simple_reg)
```

---
class: font140
# Two Promotion Comparison with log Y

`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**Questions**:

* How to interpret this regression?
* Could we also take the log of the X variable?

<!---
**Answers**:

* $\beta_0$ is the average log revenue for stores in promotion 1. Not very useful ...
* $\beta$ is (approximately) the average percentage difference in revenue between promotion 2 and promotion 1. 
  * $\exp{\hat{\beta_1}} - 1$ is the exact percentage difference...
* We cannot take the log of `Promotion 2`. This variable is either zero (not in promotion 2) or 1 (in promotion 1)
  - ... And log(0) is not defined
  - ... Thats OK, the interpretation is still nice!
---> 

---
# Three Promotion Comparison 

$$\text{Sales}_i = \beta_0 + \beta_1 \text{Promotion Type 2} + \beta_2 \text{Promotion Type 3} + \varepsilon_i$$

```{r, echo = FALSE}
full_reg <- lm(sales_in_thousands ~ as.factor(promotion), data = df)
summary(full_reg)
```

---
class: font140
# Three Promotion Comparison 

`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**Questions**:

* Why only an estimate of promotion 2 and 3 and not also promotion 1?
* How to interpret this regression?

<!---
**Answers**: 

* Now have three categories, Promotion 1, Promotion 2, Promotion 3. Can only estimate two effects since $\beta_0$ captures the average of outcome variable for left out group.
* $\beta_0$ is the average revenue for stores in Promotion 1
* $\beta_1$ is the average difference in revenue for stores in Promotion 2 compared to Promotion 1.
* $\beta_2$ is the average difference in revenue for stores in Promotion 3 compared to Promotion 1.
* $\beta_3 - \beta_2$ is the average difference in revenue between stores in Promotion 3 compared to Promotion 2.
--->

---
# Three Promotion Comparison with Log Y


$$\log(\text{Sales}_i) = \beta_0 + \beta_1 \text{Promotion Type 2} + \beta_2 \text{Promotion Type 3} + \varepsilon_i$$

```{r, echo = FALSE}
full_reg <- lm(log(sales_in_thousands) ~ as.factor(promotion), data = df)
summary(full_reg)
```

---
class: font140
# Three Promotion Comparison with Log Y

`r icons:::icon_style(icons::fontawesome("question", style = "solid"), scale = 1)`
**Questions**:

* How to interpret each coefficient from this regression?

<!---
**Answers:**

* $\beta_0$ is the average log revenue for stores in Promotion 1
* $\beta_1$ is the average percentage difference in revenue for stores in Promotion 2 compared to Promotion 1.
* $\beta_2$ is the average percentage difference in revenue for stores in Promotion 3 compared to Promotion 1.
* $\beta_3 - \beta_2$ is the average percentage difference in revenue between stores in Promotion 3 compared to Promotion 2.
--->


---
class: inverse, center, middle

# Recap

---
# Recap

* Well designed experiments deliver causal effects of marketing interventions
  - Eliminating "lurking variables" and sample selection bias

* 8 steps in the experimental method
* Analyzing data from an experiment involves descriptive statistics, data visualization and (statistical) hypothesis tests


---
class: font160
# Tips on Presenting Findings

1. Know your audience 
2. Summarize the experiment 
3. Provide context
4. Lead with a recommendation
5. Support with analysis
6. Use graphs 
7. Check the (graph) labels!

---
# License & Citation

Suggested Citation:

```{r, engine='out', eval = FALSE}
@misc{deerdsms2023,
      title={"Digital and Social Media Strategies: Field Experiments"},
      author={Lachlan Deer},
      year={2023},
      url = "https://github.com/tisem-digital-marketing/dsms-lecture-experiments"
}
```

<p style="text-align:center;"><img src="https://www.tilburguniversity.edu/sites/default/files/styles/large_width/public/image/Logo%20OSCT.png?itok=PqU9mw_l" alt="Logo" width = "200"></p>

This course adheres to the principles of the Open Science Community of Tilburg University. 
This initiative advocates for transparency and accessibility in research and teaching to all levels of society and thus creating more accountability and impact.

<p style="text-align:center;"><img src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" alt="Logo" width = "100"></p>
This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.